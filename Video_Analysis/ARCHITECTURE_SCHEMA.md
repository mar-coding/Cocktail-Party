# ğŸ—ï¸ Architecture du Projet CocktailPartyAI

## ğŸ“Š Vue d'ensemble hiÃ©rarchique

```
CocktailPartyAI/
â”‚
â”œâ”€ Cocktail-Party/          â† Vous Ãªtes ici (Analyse VidÃ©o)
â”‚  â”‚
â”‚  â”œâ”€ Scripts Principaux/
â”‚  â”‚  â”œâ”€ video_analysis_template.py      [Complet - Multi-tÃ¢ches]
â”‚  â”‚  â”œâ”€ simple_video_demo.py            [Simple - Prototype]
â”‚  â”‚  â”œâ”€ mouth_open_detector.py          [Basique - Bouche]
â”‚  â”‚  â””â”€ mouth_open_detector_improved.py [AvancÃ© - Bouche + Zoom]
â”‚  â”‚
â”‚  â”œâ”€ Documentation/
â”‚  â”‚  â”œâ”€ PROJECT_OVERVIEW.md             [Ce fichier - Vue gÃ©nÃ©rale]
â”‚  â”‚  â”œâ”€ ARCHITECTURE_SCHEMA.md          [Architecture visuelle]
â”‚  â”‚  â”œâ”€ README_VIDEO.md                 [Guide utilisateur]
â”‚  â”‚  â”œâ”€ VIDEO_ANALYSIS_GUIDE.md         [Guide technique]
â”‚  â”‚  â””â”€ MOUTH_DETECTION_GUIDE.md        [Guide dÃ©tection bouche]
â”‚  â”‚
â”‚  â””â”€ DonnÃ©es/
â”‚     â”œâ”€ videoplayback.mp4               [VidÃ©o test]
â”‚     â”œâ”€ discussion.wav                  [Audio test]
â”‚     â”œâ”€ discussion.rttm                 [Annotations]
â”‚     â””â”€ IGN UK Podcast.mp3              [Podcast multi-speakers]
â”‚
â””â”€ diart/                    â† Diarisation Audio (sÃ©parÃ©)
   â””â”€ [BibliothÃ¨que speaker diarization]
```

---

## ğŸ”„ Flux de donnÃ©es

### **Pipeline VidÃ©o Complet**

```
ğŸ“¹ Source VidÃ©o
    â”‚
    â”œâ”€ Webcam (source=0)
    â”œâ”€ Fichier vidÃ©o (.mp4, .avi)
    â””â”€ Stream (rtsp://)
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   cv2.VideoCapture()          â”‚  â† Capture frame par frame
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frame (image BGR)           â”‚  â† 1280x720 pixels par exemple
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MediaPipe Face Detection    â”‚  â† Trouve les visages
â”‚   (DÃ©tection rapide)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Liste de bounding boxes     â”‚  â† [(x,y,w,h), (x,y,w,h), ...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
    Pour chaque visage:
    â”‚
    â”œâ”€ Si petit visage (< 80px) ?
    â”‚   â”‚
    â”‚   â†“ OUI
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â”‚  Zoom x2-x3 (ROI)    â”‚  â† AmÃ©lioration visages Ã©loignÃ©s
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MediaPipe Face Mesh         â”‚  â† DÃ©tecte 468 landmarks
â”‚   (DÃ©tection prÃ©cise)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Points de la bouche         â”‚  â† Points 13, 14, 61, 291, etc.
â”‚   (9 points supÃ©rieurs)       â”‚
â”‚   (9 points infÃ©rieurs)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Calcul MAR                  â”‚  â† Mouth Aspect Ratio
â”‚   vertical / horizontal       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Filtrage temporel           â”‚  â† Lissage sur 5 frames
â”‚   (Vote majoritaire)          â”‚     (Ã©vite flickering)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DÃ©cision: Bouche ouverte ?  â”‚  â† MAR > seuil (0.25)
â”‚   True / False                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Annotation de la frame      â”‚  â† Dessiner boÃ®tes, labels
â”‚   - Bounding box (vert/rouge) â”‚
â”‚   - Label "BOUCHE OUVERTE"    â”‚
â”‚   - Ratio MAR                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Affichage / Sauvegarde      â”‚
â”‚   - cv2.imshow()             â”‚  â† Affichage en direct
â”‚   - VideoWriter()            â”‚  â† Sauvegarde en .mp4
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Architecture des Classes

### **1. video_analysis_template.py**

```
VideoAnalyzer
â”œâ”€ __init__(video_source)
â”‚  â”œâ”€ cap = cv2.VideoCapture(source)
â”‚  â”œâ”€ face_detector = FaceDetector()
â”‚  â”œâ”€ mouth_detector = MouthMovementDetector()
â”‚  â””â”€ audio_analyzer = AudioAnalyzer()
â”‚
â”œâ”€ process_frame(frame)
â”‚  â”œâ”€ faces = face_detector.detect_faces(frame)
â”‚  â”œâ”€ for each face:
â”‚  â”‚  â””â”€ face.is_talking = mouth_detector.detect_talking(frame, face)
â”‚  â””â”€ return annotated_frame, faces
â”‚
â”œâ”€ annotate_frame(frame, faces)
â”‚  â”œâ”€ Draw bounding boxes
â”‚  â”œâ”€ Draw labels
â”‚  â””â”€ return annotated_frame
â”‚
â””â”€ run(display, output_path)
   â”œâ”€ while True:
   â”‚  â”œâ”€ ret, frame = cap.read()
   â”‚  â”œâ”€ annotated, faces = process_frame(frame)
   â”‚  â”œâ”€ cv2.imshow() if display
   â”‚  â””â”€ video_writer.write() if output_path
   â””â”€ cleanup()

FaceDetector
â”œâ”€ __init__(min_detection_confidence)
â”‚  â””â”€ mp_face_detection.FaceDetection()
â”‚
â””â”€ detect_faces(frame)
   â”œâ”€ Convert BGR â†’ RGB
   â”œâ”€ results = face_detection.process(rgb_frame)
   â””â”€ return List[Face]

MouthMovementDetector
â”œâ”€ __init__()
â”‚  â”œâ”€ mp_face_mesh.FaceMesh()
â”‚  â””â”€ mouth_history = {}
â”‚
â”œâ”€ calculate_mouth_aspect_ratio(landmarks, shape)
â”‚  â”œâ”€ upper_lip = landmarks[13]
â”‚  â”œâ”€ lower_lip = landmarks[14]
â”‚  â”œâ”€ left_corner = landmarks[61]
â”‚  â”œâ”€ right_corner = landmarks[291]
â”‚  â”œâ”€ vertical = |lower.y - upper.y|
â”‚  â”œâ”€ horizontal = |right.x - left.x|
â”‚  â””â”€ return vertical / horizontal
â”‚
â””â”€ detect_talking(frame, face, threshold)
   â”œâ”€ Extract face ROI
   â”œâ”€ results = face_mesh.process(roi)
   â”œâ”€ mar = calculate_mouth_aspect_ratio()
   â”œâ”€ mouth_history.append(mar)
   â”œâ”€ variance = np.var(mouth_history)
   â””â”€ return variance > threshold

AudioAnalyzer
â”œâ”€ __init__(sample_rate, chunk_size)
â””â”€ detect_speech(audio_chunk, threshold)
   â”œâ”€ energy = calculate_audio_energy()
   â””â”€ return energy > threshold
```

---

### **2. mouth_open_detector_improved.py**

```
ImprovedMouthOpenDetector
â”œâ”€ __init__(mouth_open_threshold, min_face_size)
â”‚  â”œâ”€ mp_face_mesh.FaceMesh()
â”‚  â”œâ”€ mp_face_detection.FaceDetection()
â”‚  â”œâ”€ mouth_history = {}
â”‚  â””â”€ stats = {}
â”‚
â”œâ”€ detect_faces_locations(frame)
â”‚  â”œâ”€ results = face_detection.process(frame)
â”‚  â””â”€ return list of bboxes  [Rapide - PrÃ©-localisation]
â”‚
â”œâ”€ upscale_face_roi(frame, bbox, target_size=200)
â”‚  â”œâ”€ Extract ROI with padding
â”‚  â”œâ”€ Calculate scale_factor
â”‚  â”œâ”€ if scale > 1: cv2.resize(roi, INTER_CUBIC)
â”‚  â””â”€ return upscaled_roi, scale_factor  [AmÃ©liore petits visages]
â”‚
â”œâ”€ calculate_mouth_ratio_robust(landmarks, shape)
â”‚  â”œâ”€ Method 1: Central points (13, 14, 61, 291)
â”‚  â”œâ”€ Method 2: Average 9 upper + 9 lower points
â”‚  â”œâ”€ vertical = (method1 + method2) / 2
â”‚  â””â”€ return vertical / horizontal  [Plus robuste]
â”‚
â”œâ”€ smooth_mouth_state(face_id, is_open)
â”‚  â”œâ”€ mouth_history[face_id].append(is_open)
â”‚  â”œâ”€ open_count = sum(history)
â”‚  â””â”€ return majority_vote  [Anti-flickering]
â”‚
â”œâ”€ process_single_face(frame, bbox, face_id)
â”‚  â”œâ”€ if face_size < min_face_size:
â”‚  â”‚  â””â”€ roi, scale = upscale_face_roi()  [Zoom si nÃ©cessaire]
â”‚  â”œâ”€ results = face_mesh.process(roi)
â”‚  â”œâ”€ mar = calculate_mouth_ratio_robust()
â”‚  â”œâ”€ is_open_raw = mar > threshold
â”‚  â”œâ”€ is_open = smooth_mouth_state()
â”‚  â””â”€ return face_data
â”‚
â”œâ”€ process_frame(frame)
â”‚  â”œâ”€ bboxes = detect_faces_locations(frame)  [Ã‰tape 1: Localisation]
â”‚  â”œâ”€ for bbox in bboxes:
â”‚  â”‚  â””â”€ face_data = process_single_face()    [Ã‰tape 2: Analyse dÃ©taillÃ©e]
â”‚  â””â”€ return annotated_frame, faces_data
â”‚
â””â”€ run(source)
   â”œâ”€ cap = cv2.VideoCapture(source)
   â”œâ”€ while True:
   â”‚  â”œâ”€ frame = cap.read()
   â”‚  â”œâ”€ annotated, faces = process_frame(frame)
   â”‚  â””â”€ cv2.imshow()
   â””â”€ cleanup()
```

---

## ğŸ¯ Comparaison architecturale

### **Architecture Simple (simple_video_demo.py)**

```
SimpleVideoAnalyzer
â”œâ”€ Tout dans une seule classe
â”œâ”€ Pas de sÃ©paration FaceDetector / MouthDetector
â””â”€ MÃ©thodes intÃ©grÃ©es
```

**Avantages:**

- âœ… Facile Ã  comprendre
- âœ… Code court (~140 lignes)
- âœ… Rapide Ã  modifier

**InconvÃ©nients:**

- âŒ Moins modulaire
- âŒ Difficile Ã  Ã©tendre
- âŒ RÃ©utilisation limitÃ©e

---

### **Architecture Modulaire (video_analysis_template.py)**

```
VideoAnalyzer
â”œâ”€ FaceDetector       [Module sÃ©parÃ©]
â”œâ”€ MouthDetector      [Module sÃ©parÃ©]
â””â”€ AudioAnalyzer      [Module sÃ©parÃ©]
```

**Avantages:**

- âœ… TrÃ¨s modulaire
- âœ… Facile Ã  tester individuellement
- âœ… RÃ©utilisable
- âœ… Extensible

**InconvÃ©nients:**

- âŒ Plus de code (~385 lignes)
- âŒ Plus complexe pour dÃ©buter

---

### **Architecture OptimisÃ©e (mouth_open_detector_improved.py)**

```
ImprovedMouthOpenDetector
â”œâ”€ Face Detection (prÃ©-localisation)
â”œâ”€ Upscaling (traitement adaptatif)
â”œâ”€ Face Mesh (dÃ©tection prÃ©cise)
â”œâ”€ Calcul robuste (multi-points)
â””â”€ Filtrage temporel (lissage)
```

**Avantages:**

- âœ… DÃ©tecte visages Ã©loignÃ©s
- âœ… Moins de faux positifs
- âœ… Robuste aux variations

**InconvÃ©nients:**

- âŒ Plus lent (30-50%)
- âŒ Complexe (~450 lignes)

---

## ğŸ” DÃ©tection multi-Ã©chelle expliquÃ©e

### **ProblÃ¨me: Visages Ã©loignÃ©s**

```
CamÃ©ra â†’ ScÃ¨ne â†’ Extraction frame
            â”‚
            â”œâ”€ Personne proche (200px)   âœ… DÃ©tectÃ© facilement
            â”œâ”€ Personne moyenne (100px)  âš ï¸ DÃ©tectÃ© difficilement
            â””â”€ Personne loin (50px)      âŒ Perdu ou imprÃ©cis
```

### **Solution: Zoom adaptatif**

```
Frame complÃ¨te (1280x720)
    â”‚
    â†“ Face Detection rapide
    â”‚
    â”œâ”€ Visage A (200px) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Process normal
    â”‚                                  â”‚
    â”‚                                  â†“
    â”‚                               Face Mesh â†’ MAR â†’ DÃ©cision
    â”‚
    â”œâ”€ Visage B (80px) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Zoom x2 (160px)
    â”‚                                  â”‚
    â”‚                                  â†“
    â”‚                               Face Mesh â†’ MAR â†’ DÃ©cision
    â”‚
    â””â”€ Visage C (40px) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Zoom x4 (160px)
                                       â”‚
                                       â†“
                                    Face Mesh â†’ MAR â†’ DÃ©cision
```

**RÃ©sultat:**

- Tous les visages traitÃ©s Ã  taille optimale
- Landmarks prÃ©cis mÃªme pour petits visages
- Pas de perte d'information

---

## ğŸ“Š Flux de dÃ©cision MAR

```
Extraction Landmarks
    â”‚
    â†“
Calcul distances
    â”‚
    â”œâ”€ Vertical: |lÃ¨vre_sup - lÃ¨vre_inf|
    â””â”€ Horizontal: |coin_gauche - coin_droit|
    â”‚
    â†“
MAR = Vertical / Horizontal
    â”‚
    â†“
MAR < 0.15 â”€â”€â”€â”€â”€â”€â”€â”€â†’ Bouche fermÃ©e ğŸ˜
    â”‚
0.15 â‰¤ MAR < 0.25 â”€â†’ LÃ©gÃ¨rement ouverte ğŸ™‚
    â”‚
MAR â‰¥ 0.25 â”€â”€â”€â”€â”€â”€â”€â”€â†’ Bouche ouverte ğŸ˜®
    â”‚
MAR > 0.35 â”€â”€â”€â”€â”€â”€â”€â”€â†’ TrÃ¨s ouverte ğŸ˜²
```

---

## ğŸ¨ Pipeline d'annotation

```
Frame originale
    â”‚
    â†“
Pour chaque visage dÃ©tectÃ©:
    â”‚
    â”œâ”€ Bouche ouverte?
    â”‚  â”œâ”€ OUI â†’ color = (0, 255, 0)    [Vert]
    â”‚  â””â”€ NON â†’ color = (255, 0, 0)     [Rouge]
    â”‚
    â”œâ”€ Dessiner bounding box
    â”‚  â””â”€ cv2.rectangle(frame, (x,y), (x+w, y+h), color, 2)
    â”‚
    â”œâ”€ Dessiner label
    â”‚  â”œâ”€ text = "Face {id}: BOUCHE OUVERTE"
    â”‚  â””â”€ cv2.putText(frame, text, position, font, color)
    â”‚
    â”œâ”€ Dessiner MAR
    â”‚  â””â”€ text = f"MAR: {mar:.3f}"
    â”‚
    â””â”€ (Optionnel) Dessiner landmarks
       â””â”€ for point in mouth_landmarks:
          â””â”€ cv2.circle(frame, point, 2, (0,255,0), -1)
    â”‚
    â†“
Frame annotÃ©e
    â”‚
    â”œâ”€ Affichage: cv2.imshow()
    â””â”€ Sauvegarde: video_writer.write()
```

---

## ğŸ”„ IntÃ©gration Audio-VidÃ©o (future)

```
Stream VidÃ©o                    Stream Audio
    â”‚                               â”‚
    â†“                               â†“
Face Detection              VAD (Voice Activity)
    â”‚                               â”‚
    â†“                               â†“
Mouth Movement             Spectral Analysis
    â”‚                               â”‚
    â†“                               â†“
MAR > 0.25?                Energy > threshold?
    â”‚                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Fusion multimodale  â”‚
    â”‚                     â”‚
    â”‚ Bouche ouverte AND  â”‚
    â”‚ Audio prÃ©sent       â”‚
    â”‚         â†“           â”‚
    â”‚   Parole confirmÃ©e  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
    Attribution speaker
```

**Avantages de la fusion:**

- âœ… Ã‰limine faux positifs (bÃ¢illement sans son)
- âœ… Meilleure attribution (qui parle vraiment)
- âœ… Synchronisation audio-vidÃ©o
- âœ… Cocktail party problem rÃ©solu

---

## ğŸ¯ Choix architectural selon cas d'usage

```
Cas d'usage                     â†’ Fichier recommandÃ©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Prototype rapide                â†’ simple_video_demo.py
Application production          â†’ video_analysis_template.py
DÃ©tection bouche seule (proche) â†’ mouth_open_detector.py
DÃ©tection bouche (Ã©loignÃ©)      â†’ mouth_open_detector_improved.py
Diagnostic installation         â†’ test_setup.py
Apprentissage                   â†’ Lire GUIDES .md
```

---

## ğŸ’¾ Flux de sauvegarde vidÃ©o

```
Initialisation
    â”‚
    â†“
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
writer = cv2.VideoWriter(
    filename='output.mp4',
    fourcc=fourcc,
    fps=30,
    frameSize=(1280, 720)
)
    â”‚
    â†“
Boucle traitement
    â”‚
    â”œâ”€ frame = cap.read()
    â”œâ”€ annotated = process_frame(frame)
    â””â”€ writer.write(annotated)  [Ã‰criture frame annotÃ©e]
    â”‚
    â†“
Finalisation
    â”‚
    â”œâ”€ writer.release()
    â””â”€ cap.release()
```

---

## ğŸš€ Optimisations de performance

### **Niveau 1: RÃ©duire rÃ©solution**

```python
frame = cv2.resize(frame, (640, 480))  # Au lieu de 1920x1080
```

**Gain:** ~60% plus rapide

### **Niveau 2: Skip frames**

```python
if frame_count % 2 == 0:  # Traiter 1 frame sur 2
    process_frame(frame)
```

**Gain:** ~50% plus rapide

### **Niveau 3: Limiter visages**

```python
FaceMesh(max_num_faces=3)  # Au lieu de 10
```

**Gain:** Variable selon scÃ¨ne

### **Niveau 4: ROI intelligente**

```python
# Ne traiter que les zones avec mouvement
if has_motion(frame):
    process_frame(frame)
```

**Gain:** ~70% plus rapide (scÃ¨nes statiques)

---

## ğŸ“ˆ ScalabilitÃ©

```
1 visage    â†’ 30 FPS (temps rÃ©el excellent)
3 visages   â†’ 20 FPS (temps rÃ©el bon)
5 visages   â†’ 12 FPS (temps rÃ©el acceptable)
10 visages  â†’ 6 FPS  (limite temps rÃ©el)
20+ visages â†’ < 3 FPS (offline processing)
```

**Solutions pour scaling:**

- GPU acceleration (MediaPipe supporte GPU)
- Traitement parallÃ¨le (multiprocessing)
- Batch processing (traiter frames par groupes)
- Downsampling adaptatif (rÃ©duire rÃ©solution si trop de visages)

